## TÃ¼rkÃ§e Auto-GPT: Otonom Bir GPT-4 Deneyimi 


Auto-GPT, GPT-4 dil modelinin yeteneklerini sergileyen deneysel bir aÃ§Ä±k kaynaklÄ± uygulamadÄ±r. GPT-4 tarafÄ±ndan yÃ¶netilen bu program, belirlediÄŸiniz hedefe Ã¶zel bir ÅŸekilde ulaÅŸmak iÃ§in Ã§alÄ±ÅŸÄ±yor. Tamamen otonom olarak Ã§alÄ±ÅŸan GPT-4'Ã¼n ilk Ã¶rneklerinden biri olan Auto-GPT, yapay zeka ile mÃ¼mkÃ¼n olanÄ±n sÄ±nÄ±rlarÄ±nÄ± zorluyor.

## ğŸš€ Features

- ğŸŒ Arama ve bilgi toplama iÃ§in internet eriÅŸimi
- ğŸ’¾ Uzun SÃ¼reli ve KÄ±sa SÃ¼reli hafÄ±za yÃ¶netimi
- ğŸ§  Metin Ã¼retimi iÃ§in GPT-4 Ã¶rnekleri
- ğŸ”— PopÃ¼ler web sitelerine ve platformlara eriÅŸim
- ğŸ—ƒï¸ GPT-3.5 ile dosya depolama ve Ã¶zetleme

## ğŸ“‹ Gereksinimler

- Python 3.8 veya Ã¼stÃ¼ (adÄ±mlar: [Windows iÃ§in](https://www.tutorialspoint.com/how-to-install-python-in-windows) /
                                 [Mac iÃ§in](https://www.dataquest.io/blog/installing-python-on-mac/))
- [OpenAI API key](https://platform.openai.com/account/api-keys)

### Opsiyonel
- ElevenLabs Key (Yapay Zeka'nÄ±n konuÅŸmasÄ±nÄ± istiyorsanÄ±z)

## âš ï¸ OpenAI API Keys konfigÃ¼rasyon âš ï¸ 

OpenAI API anahtarÄ±nÄ±zÄ± ÅŸu adresten alÄ±n:: https://platform.openai.com/account/api-keys.

#### **LÃœTFEN DEVAM ETMEDEN Ã–NCE BU ADIMI YAPTIÄINIZDAN EMÄ°N OLUN, YOKSA HÄ°Ã‡BÄ°R ÅEY Ã‡ALIÅMAZ!**

## ğŸ’¾ Kurulum

Auto-GPT'yi yÃ¼klemek iÃ§in ÅŸu adÄ±mlarÄ± izleyin:

1. YukarÄ±da listelenen tÃ¼m **gereksinimlere** sahip olduÄŸunuzdan emin olun, yoksa yÃ¼kleyin/alÄ±n

_AÅŸaÄŸÄ±daki komutlarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in, bilgisayarÄ±nÄ±zdaki bir klasÃ¶re gidip Ã¼stteki klasÃ¶r yoluna 'CMD' yazarak bir CMD, Bash veya Powershell penceresi aÃ§Ä±n, ardÄ±ndan enter tuÅŸuna basÄ±n._

2. Depoyu klonlayÄ±n: Bu adÄ±m iÃ§in Git'in kurulu olmasÄ± gerekir.Proje dizinine gidin: (Bunu CMD pencerenize yazÄ±n, CMD penceresinde az Ã¶nce indirdiÄŸiniz depoya gitmeyi hedefliyorsunuz)

    ```bash
    git clone https://github.com/YusufBehramBayindir/Auto-GPT.git
    ```

3. Deponun indirildiÄŸi dizine gidin

    ```bash
    cd Auto-GPT
    ```

4. Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± kurun

    ```bash
    pip install -r requirements.txt
    ```

5. Auto-GPT'yi yapÄ±landÄ±rÄ±n
    1. Ana "/Auto-GPT" klasÃ¶rÃ¼nde ".env.template" adlÄ± dosyayÄ± bulun.
    2. ".template" uzantÄ±sÄ±nÄ± kaldÄ±rarak bu dosyanÄ±n ".env" adlÄ± bir kopyasÄ±nÄ± oluÅŸturun. En kolay yol, bunu bir komut istemi/terminal penceresinde `cp .env.template .env` yapmaktÄ±r.
    3. `.env` dosyasÄ±nÄ± bir metin dÃ¼zenleyicide aÃ§Ä±n. _Not: Nokta ile baÅŸlayan dosyalar Ä°ÅŸletim Sisteminiz tarafÄ±ndan gizlenmiÅŸ olabilir._
    4. "OPENAI_API_KEY=" yazan satÄ±rÄ± bulun.
    5. `"="` iÅŸaretinden sonra benzersiz OpenAI API AnahtarÄ±nÄ±zÄ± girin (tÄ±rnak iÅŸaretleri veya boÅŸluklar olmadan).
    6. Kullanmak istediÄŸiniz hizmetler iÃ§in diÄŸer API anahtarlarÄ±nÄ± veya Simgelerini girin.
    7. ".env" dosyasÄ±nÄ± kaydedip kapatÄ±n.

    Bu adÄ±mlarÄ± tamamlayarak, projeniz iÃ§in API AnahtarlarÄ±nÄ± doÄŸru ÅŸekilde yapÄ±landÄ±rdÄ±nÄ±z.
   
   - OpenAI API anahtarÄ±nÄ±zÄ± almak iÃ§in [OpenAI API AnahtarlarÄ± YapÄ±landÄ±rmasÄ±](#openai-api-keys-configuration) konusuna bakÄ±n.
   - ElevenLabs API anahtarÄ±nÄ±zÄ± ÅŸu adresten edinin: https://elevenlabs.io. Web sitesindeki "Profil" sekmesini kullanarak xi-api-key'inizi gÃ¶rÃ¼ntÃ¼leyebilirsiniz.
   - GPT'yi bir Azure Ã¶rneÄŸinde kullanmak istiyorsanÄ±z, `USE_AZURE` Ã¶ÄŸresini `True` olarak ayarlayÄ±n ve ardÄ±ndan ÅŸu adÄ±mlarÄ± izleyin:
     -  `azure.yaml.template` Ã¶ÄŸresini `azure.yaml`  olarak yeniden adlandÄ±rÄ± ve `azure_api_base`, `azure_api_version` ve ilgili modeller iÃ§in tÃ¼m daÄŸÄ±tÄ±m kimliklerini `azure_model_map` bÃ¶lÃ¼mÃ¼nde saÄŸlayÄ±n:
       - `fast_llm_model_deployment_id` - gpt-3.5-turbo veya gpt-4 deployment ID
       - `smart_llm_model_deployment_id` - gpt-4 deployment ID
       - `embedding_model_deployment_id` - text-embedding-ada-002 v2  deployment ID
     - LÃ¼tfen bu deÄŸerlerin tÃ¼mÃ¼nÃ¼ Ã§ift tÄ±rnaklÄ± dizeler olarak belirtin
        ```yaml
        # KÃ¶ÅŸeli parantezler (<>) iÃ§indeki dizeyi kendi kimliÄŸiniz ile deÄŸiÅŸtirin
        azure_model_map:
          fast_llm_model_deployment_id: "<my-fast-llm-deployment-id>"
         ...
       ```

     - AyrÄ±ntÄ±lar burada bulunabilir: https://pypi.org/project/openai/ in the `Microsoft Azure Endpoints` section and here: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings?tabs=command-line for the embedding model.

## ğŸ”§ kullanÄ±m

1. Terminalinizde `autogpt` Python modÃ¼lÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±n

    ```
    python -m autogpt
    ```

2. Her eylemden sonra, komut(lar)Ä± yetkilendirmek iÃ§in seÃ§enekler arasÄ±ndan seÃ§im yapÄ±n,
programdan Ã§Ä±kÄ±n veya yapay zekaya geri bildirim saÄŸlayÄ±n.
    1. Tek bir komutu yetkilendirin, "y" girin
    2. Bir dizi _N_ sÃ¼rekli komut yetkilendirin, `y -N` girin
    3. Programdan Ã§Ä±kÄ±n, `n` girin


### Logs

Etkinlik ve hata gÃ¼nlÃ¼kleri "./output/logs" klasÃ¶rÃ¼nde bulunur.

Hata ayÄ±klama gÃ¼nlÃ¼klerini yazdÄ±rmak iÃ§in:

```
python -m autogpt --debug
```

### Komut SatÄ±rÄ± ArgÃ¼manlarÄ±
Auto-GPT'yi Ã§alÄ±ÅŸtÄ±rÄ±rken kullanabileceÄŸiniz bazÄ± yaygÄ±n argÃ¼manlar ÅŸunlardÄ±r:
> AÃ§Ä±lÄ± parantez (<>) iÃ§indeki her ÅŸeyi belirtmek istediÄŸiniz bir deÄŸerle deÄŸiÅŸtirin

* Mevcut tÃ¼m komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyin
     ``` bash
     piton -m autogpt --help
     ```
* Auto-GPT'yi farklÄ± bir AI AyarlarÄ± dosyasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n
     ``` bash
     python -m autogpt --ai-settings <dosyaadÄ±>
     ```
* Bir bellek arka ucu belirtin
     ``` bash
     python -m autogpt --use-memory <memory-backend>
     ```

> **NOT**: Bu Ã¶rneklerden bazÄ±larÄ± iÃ§in kÄ±sa yollar vardÄ±r, Ã¶rneÄŸin "--use-memory" iÃ§in "-m". Daha fazla bilgi iÃ§in "python -m autogpt --help" kullanÄ±n

## ğŸ—£ï¸ KonuÅŸma Modu
Auto-GPT iÃ§in TTS'yi _(Text-to-Speech)_  kullanmak Ã¼zere bunu kullanÄ±n

```bash
python -m autogpt --speak
```

### On bir laboratuvardan gelen adlara sahip kimlik listesi, adÄ± veya ID kullanabilirsiniz:

- Rachel : 21m00Tcm4TlvDq8ikWAM
- Domi : AZnzlk1XvdvUeBnXmlld
- Bella : EXAVITQu4vr4xnSDxMaL
- Antoni : ErXwobaYiN019PkySvjV
- Elli : MF3mGyEYCl7XYWbV9V6O
- Josh : TxGEqnHWrfWFTfGW9XjX
- Arnold : VR6AewLTigWG4xSOukaG
- Adam : pNInz6obpgDQGcFmaJgB
- Sam : yoZ06aMxZJJ28mfd3POQ

## ğŸ” Google API AnahtarlarÄ± YapÄ±landÄ±rmasÄ±

Bu bÃ¶lÃ¼m isteÄŸe baÄŸlÄ±dÄ±r, bir google aramasÄ± yaparken 429 hatasÄ±yla ilgili sorun yaÅŸÄ±yorsanÄ±z resmi google api'yi kullanÄ±n.
"google_official_search" komutunu kullanmak iÃ§in ortam deÄŸiÅŸkenlerinizde Google API anahtarlarÄ±nÄ±zÄ± ayarlamanÄ±z gerekir.
1. [Google Bulut Konsoluna](https://console.cloud.google.com/) gidin.
2. HalihazÄ±rda bir hesabÄ±nÄ±z yoksa, bir hesap oluÅŸturun ve oturum aÃ§Ä±n.
3. SayfanÄ±n Ã¼st kÄ±smÄ±ndaki "Bir Proje SeÃ§in" aÃ§Ä±lÄ±r menÃ¼sÃ¼ne ve ardÄ±ndan "Yeni Proje"ye tÄ±klayarak yeni bir proje oluÅŸturun. Bir isim verin ve "OluÅŸtur" u tÄ±klayÄ±n.
4. [API'ler ve Hizmetler Panosuna](https://console.cloud.google.com/apis/dashboard) gidin ve "API'leri ve Hizmetleri EtkinleÅŸtir"i tÄ±klayÄ±n. "Custom Search API"yi arayÄ±n ve Ã¼zerine tÄ±klayÄ±n, ardÄ±ndan "EtkinleÅŸtir"e tÄ±klayÄ±n.
5. [Kimlik Bilgileri](https://console.cloud.google.com/apis/credentials) sayfasÄ±na gidin ve "Kimlik Bilgileri OluÅŸtur"u tÄ±klayÄ±n. "API AnahtarÄ±"nÄ± seÃ§in.
6. API anahtarÄ±nÄ± kopyalayÄ±n ve makinenizde "GOOGLE_API_KEY" adlÄ± bir ortam deÄŸiÅŸkeni olarak ayarlayÄ±n. AÅŸaÄŸÄ±daki ortam deÄŸiÅŸkenlerini ayarlama konusuna bakÄ±n.
7. Projenizde Ã–zel Arama API'sini [etkinleÅŸtirin](https://console.developers.google.com/apis/api/customsearch.googleapis.com). (YayÄ±lmasÄ± iÃ§in birkaÃ§ dakika beklemeniz gerekebilir)
8. [Ã–zel Arama Motoru](https://cse.google.com/cse/all) sayfasÄ±na gidin ve "Ekle"yi tÄ±klayÄ±n.
9. YÃ¶nergeleri izleyerek arama motorunuzu kurun. TÃ¼m web'de veya belirli sitelerde arama yapmayÄ± seÃ§ebilirsiniz.
10. Arama motorunuzu oluÅŸturduktan sonra, "Denetim MasasÄ±"na ve ardÄ±ndan "Temel Bilgiler"e tÄ±klayÄ±n. "Arama motoru kimliÄŸini" kopyalayÄ±n ve makinenizde "CUSTOM_SEARCH_ENGINE_ID" adlÄ± bir ortam deÄŸiÅŸkeni olarak ayarlayÄ±n. AÅŸaÄŸÄ±daki ortam deÄŸiÅŸkenlerini ayarlama konusuna bakÄ±n.

_Ãœcretsiz gÃ¼nlÃ¼k Ã¶zel arama kotanÄ±zÄ±n yalnÄ±zca 100 adede kadar aramaya izin verdiÄŸini unutmayÄ±n. Bu sÄ±nÄ±rÄ± artÄ±rmak iÃ§in, gÃ¼nlÃ¼k 10.000 adede kadar aramadan kar elde etmek iÃ§in projeye bir faturalandÄ±rma hesabÄ± atamanÄ±z gerekir._

### Ortam deÄŸiÅŸkenlerini ayarlama

Windows KullanÄ±cÄ±larÄ± iÃ§in:

```bash
setx GOOGLE_API_KEY "YOUR_GOOGLE_API_KEY"
setx CUSTOM_SEARCH_ENGINE_ID "YOUR_CUSTOM_SEARCH_ENGINE_ID"
```

macOS ve Linux kullanÄ±cÄ±larÄ± iÃ§in:

```bash
export GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
export CUSTOM_SEARCH_ENGINE_ID="YOUR_CUSTOM_SEARCH_ENGINE_ID"
```

## Ã–nbellek TÃ¼rÃ¼nÃ¼zÃ¼ Ayarlama

VarsayÄ±lan olarak, Auto-GPT redis veya Pinecone yerine LocalCache kullanacaktÄ±r.

Ä°kisinden birine geÃ§mek iÃ§in `MEMORY_BACKEND` ortam deÄŸiÅŸkenini istediÄŸiniz deÄŸerle deÄŸiÅŸtirin:

* "yerel" (varsayÄ±lan), yerel bir JSON Ã¶nbellek dosyasÄ± kullanÄ±r
* "pinecone", ENV ayarlarÄ±nÄ±zda yapÄ±landÄ±rdÄ±ÄŸÄ±nÄ±z Pinecone.io hesabÄ±nÄ± kullanÄ±r
* `redis`, yapÄ±landÄ±rdÄ±ÄŸÄ±nÄ±z redis Ã¶nbelleÄŸini kullanÄ±r
* `milvus`, yapÄ±landÄ±rdÄ±ÄŸÄ±nÄ±z milvus Ã¶nbelleÄŸini kullanÄ±r
* "weaviate", yapÄ±landÄ±rdÄ±ÄŸÄ±nÄ±z weaviate Ã¶nbelleÄŸini kullanÄ±r

## Memory Backend Setup

### RedsÄ±s Kurulumu
> _**DÄ°KKAT**__ \
Bu, herkesin eriÅŸebileceÄŸi ÅŸekilde tasarlanmamÄ±ÅŸtÄ±r ve gÃ¼venlik Ã¶nlemlerinden yoksundur. Bu nedenle, Redis'i ÅŸifre olmadan veya hiÃ§ internete maruz bÄ±rakmaktan kaÃ§Ä±nÄ±n.
1. Docker'Ä± (veya Windows'ta Docker Desktop'Ä±) kurun
2. Redis kapsayÄ±cÄ±sÄ±nÄ± baÅŸlatÄ±n
    ```bash
    docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest
    ```
    > Parola ayarlamak ve ek yapÄ±landÄ±rma iÃ§in https://hub.docker.com/r/redis/redis-stack-server adresine bakÄ±n.
3. `.env`de aÅŸaÄŸÄ±daki ayarlarÄ± yapÄ±n
     > AÃ§Ä±lÄ± parantez iÃ§indeki **ÅÄ°FRE**'yi deÄŸiÅŸtirin (<>)
    ```bash
    MEMORY_BACKEND=redis
    REDIS_HOST=localhost
    REDIS_PORT=6379
    REDIS_PASSWORD=<PASSWORD>
    ```

    Ä°steÄŸe baÄŸlÄ± olarak Redis'te saklanan belleÄŸin kalÄ±cÄ± olmasÄ± iÃ§in 'WIPE_REDIS_ON_START=False' ayarÄ±nÄ± yapabilirsiniz.

Redis iÃ§in bellek dizinini aÅŸaÄŸÄ±dakileri kullanarak belirleyebilirsiniz:
```bash
MEMORY_INDEX=<WHATEVER>
```

### ğŸŒ² Pinecone API Key Setup

Pinecone, herhangi bir zamanda aracÄ± iÃ§in yalnÄ±zca ilgili anÄ±larÄ±n yÃ¼klenmesine izin vererek, Ã§ok miktarda vektÃ¶r tabanlÄ± belleÄŸin depolanmasÄ±nÄ± saÄŸlar.

1. HenÃ¼z bir hesabÄ±nÄ±z yoksa [pinecone](https://app.pinecone.io/) adresine gidin ve bir hesap oluÅŸturun.
2. Ãœcret Ã¶dememek iÃ§in "BaÅŸlangÄ±Ã§" planÄ±nÄ± seÃ§in.
3. Sol kenar Ã§ubuÄŸundaki varsayÄ±lan proje altÄ±nda API anahtarÄ±nÄ±zÄ± ve bÃ¶lgenizi bulun.

`.env` dosya kÃ¼mesinde:
- `PINECONE_API_KEY`
- `PINECONE_ENV` (example: _"us-east4-gcp"_)
- `MEMORY_BACKEND=pinecone`

Alternatif olarak, bunlarÄ± komut satÄ±rÄ±ndan ayarlayabilirsiniz (geliÅŸmiÅŸ):

Windows KullanÄ±cÄ±larÄ± iÃ§in:

```bash
setx PINECONE_API_KEY "<YOUR_PINECONE_API_KEY>"
setx PINECONE_ENV "<YOUR_PINECONE_REGION>" # e.g: "us-east4-gcp"
setx MEMORY_BACKEND "pinecone"
```

macOS ve Linux kullanÄ±cÄ±larÄ± iÃ§in:

```bash
export PINECONE_API_KEY="<YOUR_PINECONE_API_KEY>"
export PINECONE_ENV="<YOUR_PINECONE_REGION>" # e.g: "us-east4-gcp"
export MEMORY_BACKEND="pinecone"
```

### Milvus Kurulumu

[Milvus](https://milvus.io/), Ã§ok bÃ¼yÃ¼k miktarda vektÃ¶r tabanlÄ± bellek depolamak ve ilgili hÄ±zlÄ± arama saÄŸlamak iÃ§in aÃ§Ä±k kaynaklÄ±, yÃ¼ksek dÃ¼zeyde Ã¶lÃ§eklenebilir bir vektÃ¶r veritabanÄ±dÄ±r.

- milvus veritabanÄ±nÄ± kurun, uyumlu sorunlarÄ± Ã¶nlemek iÃ§in pymilvus sÃ¼rÃ¼mÃ¼nÃ¼zÃ¼ ve milvus sÃ¼rÃ¼mÃ¼nÃ¼zÃ¼ aynÄ± tutun.
   - aÃ§Ä±k kaynaklÄ± kurulum [Milvus'u YÃ¼kle](https://milvus.io/docs/install_standalone-operator.md)
   - veya [Zilliz Cloud](https://zilliz.com/cloud) tarafÄ±ndan kurulum
- ".env" iÃ§indeki "MILVUS_ADDR"yi "host:ip" milvus adresinize ayarlayÄ±n.
- Milvus'u arka uÃ§ olarak etkinleÅŸtirmek iÃ§in ".env" iÃ§indeki "MEMORY_BACKEND" Ã¶ÄŸesini "milvus" olarak ayarlayÄ±n.

**Ä°steÄŸe baÄŸlÄ±:**
- milvus koleksiyon adÄ±nÄ± istediÄŸiniz gibi deÄŸiÅŸtirmek iÃ§in `.env` iÃ§inde `MILVUS_COLLECTION` ayarÄ±nÄ± yapÄ±n, `autogpt` varsayÄ±lan addÄ±r.


### Weaviate Kurulumu
[Weaviate](https://weaviate.io/) aÃ§Ä±k kaynaklÄ± bir vektÃ¶r veri tabanÄ±dÄ±r. Veri nesnelerini ve ML modellerinden vektÃ¶r katÄ±ÅŸtÄ±rmalarÄ±nÄ± depolamaya izin verir ve sorunsuz bir ÅŸekilde milyarlarca veri nesnesine Ã¶lÃ§eklendirir. [Bir Weaviate Ã¶rneÄŸi, yerel olarak (Docker kullanÄ±larak), Kubernetes Ã¼zerinde veya Weaviate Bulut Hizmetleri kullanÄ±larak oluÅŸturulabilir](https://weaviate.io/developers/weaviate/quickstart).
Hala deneysel olmasÄ±na raÄŸmen, Auto-GPT iÅŸleminin kendisinin bir Weaviate Ã¶rneÄŸini baÅŸlatmasÄ±na izin veren [Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded) desteklenmektedir. EtkinleÅŸtirmek iÃ§in, "USE_WEAVIATE_EMBEDDED" Ã¶ÄŸesini "True" olarak ayarlayÄ±n ve "weaviate-client>=3.15.4" kurulumunu pip olarak yaptÄ±ÄŸÄ±nÄ±zdan emin olun.

#### Weaviate istemcisini kurun

KullanÄ±mdan Ã¶nce Weaviate istemcisini kurun.

```
$ pip yÃ¼kleme weaviate-client
```

#### Ortam deÄŸiÅŸkenlerini ayarlama

`.env` dosyanÄ±zda aÅŸaÄŸÄ±dakileri ayarlayÄ±n:

```
MEMORY_BACKEND=weaviate
WEAVIATE_HOST="127.0.0.1" # the IP or domain of the running Weaviate instance
WEAVIATE_PORT="8080" 
WEAVIATE_PROTOCOL="http"
WEAVIATE_USERNAME="your username"
WEAVIATE_PASSWORD="your password"
WEAVIATE_API_KEY="your weaviate API key if you have one"
WEAVIATE_EMBEDDED_PATH="/home/me/.local/share/weaviate" # this is optional and indicates where the data should be persisted when running an embedded instance
USE_WEAVIATE_EMBEDDED=False # set to True to run Embedded Weaviate
MEMORY_INDEX="Autogpt" # name of the index to create for the application
```
 
## Bellek KullanÄ±mÄ±nÄ± GÃ¶rÃ¼ntÃ¼le

`--debug` bayraÄŸÄ±nÄ± kullanarak bellek kullanÄ±mÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyin :)


## ğŸ§  Bellek Ã¶n tohumlama
Bellek Ã¶n tohumlama, dosyalarÄ± belleÄŸe almanÄ±za ve Auto-GPT'yi Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce Ã¶n tohumlama yapmanÄ±za olanak tanÄ±r.

``` bash
# python data_ingestion.py -h 
usage: data_ingestion.py [-h] (--file FILE | --dir DIR) [--init] [--overlap OVERLAP] [--max_length MAX_LENGTH]

Bir dosyayÄ± veya birden fazla dosya iÃ§eren bir dizini belleÄŸe alÄ±n. Bu komut dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce .env'nizi ayarladÄ±ÄŸÄ±nÄ±zdan emin olun.

options:
  -h, --help               bu yardÄ±m mesajÄ±nÄ± gÃ¶ster ve Ã§Ä±k
  --file FILE              AlÄ±nacak dosya.
  --dir DIR                AlÄ±nacak dosyalarÄ± iÃ§eren dizin.
  --init                   BelleÄŸi baÅŸlatÄ±n ve iÃ§eriÄŸini silin (varsayÄ±lan: YanlÄ±ÅŸ)
  --overlap OVERLAP        DosyalarÄ± alÄ±rken parÃ§alar arasÄ±ndaki Ã¶rtÃ¼ÅŸme boyutu (varsayÄ±lan: 200)
  --max_length MAX_LENGTH  DosyalarÄ± alÄ±rken her parÃ§anÄ±n maksimum uzunluÄŸu (varsayÄ±lan: 4000)

# python data_ingestion.py --dir DataFolder --init --overlap 100 --max_length 2000
```
YukarÄ±daki Ã¶rnekte, komut dosyasÄ± belleÄŸi baÅŸlatÄ±r, "Auto-Gpt/autogpt/auto_gpt_workspace/DataFolder" dizini iÃ§indeki tÃ¼m dosyalarÄ±, 100'lÃ¼k parÃ§alar arasÄ±nda Ã§akÄ±ÅŸma ve her bir parÃ§anÄ±n maksimum uzunluÄŸu 2000 olacak ÅŸekilde belleÄŸe alÄ±r.

Tek bir dosyayÄ± belleÄŸe almak iÃ§in "--file" baÄŸÄ±msÄ±z deÄŸiÅŸkenini de kullanabileceÄŸinizi ve data_ingestion.py'nin yalnÄ±zca "/auto_gpt_workspace" dizini iÃ§indeki dosyalarÄ± alacaÄŸÄ±nÄ± unutmayÄ±n.

DIR yolu, auto_gpt_workspace dizinine gÃ¶redir, yani `python data_ingestion.py --dir . --init`, `auto_gpt_workspace` dizinindeki her ÅŸeyi alÄ±r.

Bu belleÄŸi "hatÄ±rladÄ±ÄŸÄ±nda" belgelerin yapay zekaya sunulma biÃ§imine ince ayar yapmak iÃ§in "maks_uzunluk" ve Ã§akÄ±ÅŸma parametrelerini ayarlayabilirsiniz:
- Ã–rtÃ¼ÅŸme deÄŸerinin ayarlanmasÄ±, AI'nÄ±n bilgileri geri Ã§aÄŸÄ±rÄ±rken her yÄ±ÄŸÄ±ndan daha fazla baÄŸlamsal bilgiye eriÅŸmesine olanak tanÄ±r, ancak daha fazla parÃ§anÄ±n oluÅŸturulmasÄ±na ve dolayÄ±sÄ±yla bellek arka uÃ§ kullanÄ±mÄ±nÄ±n ve OpenAI API isteklerinin artmasÄ±na neden olur.
- "max_length" deÄŸerinin dÃ¼ÅŸÃ¼rÃ¼lmesi, baÄŸlamda daha fazla mesaj geÃ§miÅŸine izin vererek bilgi istemi belirteÃ§lerini kaydedebilen daha fazla parÃ§a oluÅŸturacaktÄ±r, ancak aynÄ± zamanda parÃ§a sayÄ±sÄ±nÄ± da artÄ±racaktÄ±r.
- "max_length" deÄŸerini artÄ±rmak, yapay zekaya her parÃ§adan daha fazla baÄŸlamsal bilgi saÄŸlayarak oluÅŸturulan parÃ§a sayÄ±sÄ±nÄ± azaltÄ±r ve OpenAI API isteklerinde tasarruf saÄŸlar. Ancak bu, daha fazla bilgi istemi belirteci kullanabilir ve yapay zekanÄ±n kullanabileceÄŸi genel baÄŸlamÄ± azaltabilir.

Bellek Ã¶n tohumlama, ilgili verileri belleÄŸine alarak AI doÄŸruluÄŸunu artÄ±rmaya yÃ¶nelik bir tekniktir. Veri yÄ±ÄŸÄ±nlarÄ± bÃ¶lÃ¼nÃ¼r ve belleÄŸe eklenir, bu da AI'nÄ±n bunlara hÄ±zlÄ± bir ÅŸekilde eriÅŸmesine ve daha doÄŸru yanÄ±tlar Ã¼retmesine olanak tanÄ±r. BÃ¼yÃ¼k veri kÃ¼meleri iÃ§in veya belirli bilgilere hÄ±zlÄ± bir ÅŸekilde eriÅŸilmesi gerektiÄŸinde kullanÄ±ÅŸlÄ±dÄ±r. Ã–rnekler, Auto-GPT'yi Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce API veya GitHub belgelerinin alÄ±nmasÄ±nÄ± iÃ§erir.

âš ï¸ Memory olarak Redis kullanÄ±yorsanÄ±z, `.env` dosyanÄ±zda Auto-GPT'yi `WIPE_REDIS_ON_START=False` ile Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun.

âš ï¸DiÄŸer bellek arka uÃ§larÄ± iÃ§in, ÅŸu anda Auto-GPT'yi baÅŸlatÄ±rken belleÄŸi zorla siliyoruz. Bu bellek arka ucuyla veri almak iÃ§in, Otomatik GPT Ã§alÄ±ÅŸmasÄ± sÄ±rasÄ±nda istediÄŸiniz zaman "data_ingestion.py" komut dosyasÄ±nÄ± arayabilirsiniz.

AnÄ±lar, Auto-GPT Ã§alÄ±ÅŸÄ±rken alÄ±nsalar bile alÄ±ndÄ±klarÄ± anda yapay zeka tarafÄ±ndan kullanÄ±labilir.

## ğŸ’€ SÃ¼rekli Mod âš ï¸

AI'yÄ± **kullanÄ±cÄ± yetkilendirmesi olmadan** Ã§alÄ±ÅŸtÄ±rÄ±n, %100 otomatik.
SÃ¼rekli mod Ã¶nerilmez.
Potansiyel olarak tehlikelidir ve AI'nÄ±zÄ±n sonsuza kadar Ã§alÄ±ÅŸmasÄ±na veya normalde izin vermeyeceÄŸiniz eylemleri gerÃ§ekleÅŸtirmesine neden olabilir.
Kendi sorumluluÄŸunuzdadÄ±r kullanÄ±n.

1. Terminalinizde `autogpt` python modÃ¼lÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±n:

    ```bash
    python -m autogpt --speak --continuous
    ```

2. Programdan Ã§Ä±kmak iÃ§in Ctrl + C tuÅŸlarÄ±na basÄ±n

## GPT3.5 ONLY Mode

GPT4 api'ye eriÅŸiminiz yoksa, bu mod Auto-GPT'yi kullanmanÄ±za izin verecektir!

```bash
python -m autogpt --speak --gpt3only
```

Ana bilgisayarÄ±n sistemine ve verilerine herhangi bir zarar gelmemesi iÃ§in yÃ¼ksek gÃ¼venlik Ã¶nlemleri gerektiren gÃ¶revler iÃ§in sanal makine kullanÄ±lmasÄ± Ã¶nerilir.

## ğŸ–¼ GÃ¶rÃ¼ntÃ¼ OluÅŸturma

VarsayÄ±lan olarak Auto-GPT, gÃ¶rÃ¼ntÃ¼ oluÅŸturma iÃ§in DALL-e'yi kullanÄ±r. Stable Diffusion'Ä± kullanmak iÃ§in [Hugging Face API Simgesi](https://huggingface.co/settings/tokens) gereklidir.

Bir jetonunuz olduÄŸunda, ".env" dosyanÄ±zda ÅŸu deÄŸiÅŸkenleri ayarlayÄ±n:

```bash
IMAGE_PROVIDER=sd
HUGGINGFACE_API_TOKEN="YOUR_HUGGINGFACE_API_TOKEN"
```

## Selenium
```bash
sudo Xvfb :10 -ac -screen 0 1024x768x24 & DISPLAY=:10 <YOUR_CLIENT>
```

## âš ï¸ sÄ±nÄ±rlamalar

Bu deney, GPT-4'Ã¼n potansiyelini sergilemeyi amaÃ§lamaktadÄ±r, ancak bazÄ± sÄ±nÄ±rlamalarla birlikte gelir:

1. ParlatÄ±lmÄ±ÅŸ bir uygulama veya Ã¼rÃ¼n deÄŸil, sadece bir deney
2. KarmaÅŸÄ±k, gerÃ§ek dÃ¼nyadaki iÅŸ senaryolarÄ±nda iyi performans gÃ¶stermeyebilir. AslÄ±nda, gerÃ§ekten yaparsa, lÃ¼tfen sonuÃ§larÄ±nÄ±zÄ± paylaÅŸÄ±n!
3. Ã‡alÄ±ÅŸtÄ±rmasÄ± oldukÃ§a pahalÄ±dÄ±r, bu nedenle OpenAI ile API anahtar limitlerinizi belirleyin ve izleyin!

## ğŸ›¡Feragatname

Bu proje, Auto-GPT, deneysel bir uygulamadÄ±r ve aÃ§Ä±k veya zÄ±mni herhangi bir garanti olmaksÄ±zÄ±n "olduÄŸu gibi" saÄŸlanmaktadÄ±r. Bu yazÄ±lÄ±mÄ± kullanarak, veri kaybÄ±, sistem arÄ±zasÄ± veya ortaya Ã§Ä±kabilecek diÄŸer sorunlar dahil ancak bunlarla sÄ±nÄ±rlÄ± olmamak Ã¼zere, kullanÄ±mÄ±yla ilgili tÃ¼m riskleri Ã¼stlenmeyi kabul edersiniz.

Bu projenin geliÅŸtiricileri ve katkÄ±da bulunanlarÄ±, bu yazÄ±lÄ±mÄ±n kullanÄ±lmasÄ± sonucunda meydana gelebilecek herhangi bir kayÄ±p, hasar veya diÄŸer sonuÃ§lar iÃ§in herhangi bir sorumluluk veya yÃ¼kÃ¼mlÃ¼lÃ¼k kabul etmez. Auto-GPT tarafÄ±ndan saÄŸlanan bilgilere dayanarak alÄ±nan tÃ¼m kararlardan ve eylemlerden yalnÄ±zca siz sorumlusunuz.

**Token kullanÄ±mÄ± nedeniyle GPT-4 dil modeli kullanÄ±mÄ±nÄ±n pahalÄ± olabileceÄŸini lÃ¼tfen unutmayÄ±n.** Bu projeyi kullanarak, kendi belirteÃ§ kullanÄ±mÄ±nÄ±zÄ± ve ilgili maliyetleri izlemekten ve yÃ¶netmekten sorumlu olduÄŸunuzu kabul edersiniz. Beklenmeyen Ã¼cretleri Ã¶nlemek iÃ§in OpenAI API kullanÄ±mÄ±nÄ±zÄ± dÃ¼zenli olarak kontrol etmeniz ve gerekli limitleri veya uyarÄ±larÄ± ayarlamanÄ±z Ã¶nemle tavsiye edilir.

Otonom bir deney olarak Auto-GPT, gerÃ§ek dÃ¼nyadaki iÅŸ uygulamalarÄ±na veya yasal gerekliliklere uygun olmayan iÃ§erikler Ã¼retebilir veya eylemler gerÃ§ekleÅŸtirebilir. Bu yazÄ±lÄ±mÄ±n Ã§Ä±ktÄ±sÄ±na dayalÄ± olarak alÄ±nan tÃ¼m eylemlerin veya kararlarÄ±n geÃ§erli tÃ¼m yasalara, dÃ¼zenlemelere ve etik standartlara uygun olmasÄ±nÄ± saÄŸlamak sizin sorumluluÄŸunuzdadÄ±r. Bu projenin geliÅŸtiricileri ve katkÄ±da bulunanlarÄ±, bu yazÄ±lÄ±mÄ±n kullanÄ±mÄ±ndan doÄŸacak sonuÃ§lardan sorumlu tutulamaz.

Auto-GPT'yi kullanarak, geliÅŸtiricileri, katkÄ±da bulunanlarÄ± ve tÃ¼m baÄŸlÄ± taraflarÄ± her tÃ¼rlÃ¼ talep, zarar, kayÄ±p, sorumluluk, maliyet ve harcamaya (makul avukatlÄ±k Ã¼cretleri dahil) karÅŸÄ± tazmin etmeyi, savunmayÄ± ve masun tutmayÄ± kabul edersiniz. Bu yazÄ±lÄ±mÄ± kullanmanÄ±zdan veya bu ÅŸartlarÄ± ihlal etmenizden kaynaklanan.

## Testleri Ã§alÄ±ÅŸtÄ±r

TÃ¼m testleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
pytest 

```

To run just without integration tests:

```
pytest --without-integration
```

To run just without slow integration tests:

```
pytest --without-slow-integration
```

To run tests and see coverage, run the following command:

```bash
pytest --cov=autogpt --without-integration --without-slow-integration
```
